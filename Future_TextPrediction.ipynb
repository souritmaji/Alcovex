{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Future_TextPrediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/souritmaji/Alcovex/blob/main/Future_TextPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LlghumAQRJXO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import heapq\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "from keras.models import Sequential, load_model\n",
        "\n",
        "from keras.layers.core import Dense, Activation\n",
        "\n",
        "from keras.layers import LSTM\n",
        "\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'new.txt'\n",
        "text = open(path).read().lower()\n",
        "print('length of the corpus is: :', len(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4hfqlIoRiLN",
        "outputId": "542332a2-63df-4125-caef-a4ac0344870e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of the corpus is: : 119163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string"
      ],
      "metadata": {
        "id": "9ozrrzuseBYa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = open(\"new.txt\", \"r\", encoding = \"utf8\")\n",
        "lines = []\n",
        "\n",
        "for i in file:\n",
        "    lines.append(i)\n",
        "    \n",
        "data = \"\"\n",
        "\n",
        "for i in lines:\n",
        "    data = ' '. join(lines)\n",
        "    \n",
        "data = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '')\n",
        "\n",
        "translator = str.maketrans(string.punctuation, ' '*len(string.punctuation)) #map punctuation to space\n",
        "new_data = data.translate(translator)\n",
        "\n",
        "z = []\n",
        "\n",
        "for i in data.split():\n",
        "    if i not in z:\n",
        "        z.append(i)\n",
        "        \n",
        "data = ' '.join(z)\n"
      ],
      "metadata": {
        "id": "RBibXdardkQH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]+|\\S+')\n",
        "words = tokenizer.tokenize(text)"
      ],
      "metadata": {
        "id": "CppknRuhRvmi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_words = np.unique(words)\n",
        "unique_word_index = dict((c, i) for i, c in enumerate(unique_words))"
      ],
      "metadata": {
        "id": "8xfqt2f-S_A8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLDCVab8v1Xk",
        "outputId": "8f6b07f0-bcfc-4eb9-9586-a965d32b6687"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['!', '!\"', '!\",', ..., 'young', 'your', 'yourself'], dtype='<U17')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LENGTH_WORD = 5\n",
        "next_words = []\n",
        "prev_words = []\n",
        "for j in range(len(words) - LENGTH_WORD):\n",
        "     prev_words.append(words[j:j + LENGTH_WORD])\n",
        "     next_words.append(words[j + LENGTH_WORD])\n",
        "     \n",
        "print(prev_words[15])\n",
        "print(next_words[15])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSsQ_Fx3TDS8",
        "outputId": "6ef9af57-c7bb-47dd-fa50-55b04c869728"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['in', 'his', 'bed', 'into', 'a']\n",
            "horrible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.zeros((len(prev_words), LENGTH_WORD, len(unique_words)), dtype=bool)\n",
        "Y = np.zeros((len(next_words), len(unique_words)), dtype=bool)"
      ],
      "metadata": {
        "id": "t1iwTlMyBuo9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for i, each_words in enumerate(prev_words):\n",
        "  #  print(\"First : \" ,each_words)\n",
        "   for j, each_word in enumerate(each_words):\n",
        "        # if count == 10:\n",
        "        #   break\n",
        "        # print(\"Second : \", each_word)\n",
        "        count += 1\n",
        "        X[i, j, unique_word_index[each_word]] = 1\n",
        "   Y[i, unique_word_index[next_words[i]]] = 1\n",
        "  #  if count == 10:\n",
        "  #         break\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0eJT_PCHTGVr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(LENGTH_WORD, len(unique_words))))\n",
        "model.add(Dense(len(unique_words)))\n",
        "model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "Dh5ZJ2CTTK5T"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = RMSprop(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "history = model.fit(X, Y, validation_split=0.1, batch_size=64, epochs=100, shuffle=True).history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q2zZE6zTQ_3",
        "outputId": "f4125d1c-8a80-4fe7-d64f-4e7c11f667a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "348/348 [==============================] - 29s 73ms/step - loss: 2.1002 - accuracy: 0.7771 - val_loss: 7.3653 - val_accuracy: 0.0782\n",
            "Epoch 2/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.9652 - accuracy: 0.7913 - val_loss: 7.3729 - val_accuracy: 0.0749\n",
            "Epoch 3/100\n",
            "348/348 [==============================] - 25s 71ms/step - loss: 1.9474 - accuracy: 0.7934 - val_loss: 7.3899 - val_accuracy: 0.0741\n",
            "Epoch 4/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.9317 - accuracy: 0.7959 - val_loss: 7.3825 - val_accuracy: 0.0790\n",
            "Epoch 5/100\n",
            "348/348 [==============================] - 25s 71ms/step - loss: 1.9188 - accuracy: 0.7957 - val_loss: 7.4125 - val_accuracy: 0.0810\n",
            "Epoch 6/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.9213 - accuracy: 0.7945 - val_loss: 7.4189 - val_accuracy: 0.0737\n",
            "Epoch 7/100\n",
            "348/348 [==============================] - 25s 71ms/step - loss: 1.9159 - accuracy: 0.7947 - val_loss: 7.3551 - val_accuracy: 0.0737\n",
            "Epoch 8/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.9150 - accuracy: 0.7961 - val_loss: 7.4001 - val_accuracy: 0.0701\n",
            "Epoch 9/100\n",
            "348/348 [==============================] - 26s 76ms/step - loss: 1.8903 - accuracy: 0.7977 - val_loss: 7.4261 - val_accuracy: 0.0693\n",
            "Epoch 10/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.9024 - accuracy: 0.7971 - val_loss: 7.4086 - val_accuracy: 0.0680\n",
            "Epoch 11/100\n",
            "348/348 [==============================] - 25s 71ms/step - loss: 1.8993 - accuracy: 0.7960 - val_loss: 7.4129 - val_accuracy: 0.0709\n",
            "Epoch 12/100\n",
            "348/348 [==============================] - 25s 71ms/step - loss: 1.8865 - accuracy: 0.7992 - val_loss: 7.3977 - val_accuracy: 0.0713\n",
            "Epoch 13/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.8799 - accuracy: 0.8008 - val_loss: 7.3973 - val_accuracy: 0.0737\n",
            "Epoch 14/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.8804 - accuracy: 0.7996 - val_loss: 7.4457 - val_accuracy: 0.0689\n",
            "Epoch 15/100\n",
            "348/348 [==============================] - 25s 71ms/step - loss: 1.8673 - accuracy: 0.8022 - val_loss: 7.4000 - val_accuracy: 0.0733\n",
            "Epoch 16/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.8727 - accuracy: 0.7986 - val_loss: 7.4058 - val_accuracy: 0.0705\n",
            "Epoch 17/100\n",
            "348/348 [==============================] - 25s 71ms/step - loss: 1.8751 - accuracy: 0.8021 - val_loss: 7.3948 - val_accuracy: 0.0733\n",
            "Epoch 18/100\n",
            "348/348 [==============================] - 25s 71ms/step - loss: 1.8748 - accuracy: 0.7991 - val_loss: 7.4137 - val_accuracy: 0.0676\n",
            "Epoch 19/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.8593 - accuracy: 0.8032 - val_loss: 7.4353 - val_accuracy: 0.0761\n",
            "Epoch 20/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.8660 - accuracy: 0.8011 - val_loss: 7.4101 - val_accuracy: 0.0733\n",
            "Epoch 21/100\n",
            "348/348 [==============================] - 25s 73ms/step - loss: 1.8560 - accuracy: 0.8059 - val_loss: 7.3840 - val_accuracy: 0.0725\n",
            "Epoch 22/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.8485 - accuracy: 0.8034 - val_loss: 7.4233 - val_accuracy: 0.0668\n",
            "Epoch 23/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.8582 - accuracy: 0.8005 - val_loss: 7.3722 - val_accuracy: 0.0749\n",
            "Epoch 24/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.8522 - accuracy: 0.8033 - val_loss: 7.4274 - val_accuracy: 0.0749\n",
            "Epoch 25/100\n",
            "348/348 [==============================] - 25s 71ms/step - loss: 1.8367 - accuracy: 0.8056 - val_loss: 7.4179 - val_accuracy: 0.0632\n",
            "Epoch 26/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.8448 - accuracy: 0.8034 - val_loss: 7.4132 - val_accuracy: 0.0668\n",
            "Epoch 27/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.8330 - accuracy: 0.8068 - val_loss: 7.4496 - val_accuracy: 0.0672\n",
            "Epoch 28/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.8355 - accuracy: 0.8047 - val_loss: 7.4020 - val_accuracy: 0.0648\n",
            "Epoch 29/100\n",
            "348/348 [==============================] - 25s 71ms/step - loss: 1.8340 - accuracy: 0.8042 - val_loss: 7.4480 - val_accuracy: 0.0624\n",
            "Epoch 30/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.8332 - accuracy: 0.8057 - val_loss: 7.3764 - val_accuracy: 0.0668\n",
            "Epoch 31/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.8325 - accuracy: 0.8075 - val_loss: 7.3981 - val_accuracy: 0.0652\n",
            "Epoch 32/100\n",
            "348/348 [==============================] - 25s 73ms/step - loss: 1.8243 - accuracy: 0.8073 - val_loss: 7.4058 - val_accuracy: 0.0693\n",
            "Epoch 33/100\n",
            "348/348 [==============================] - 26s 74ms/step - loss: 1.8332 - accuracy: 0.8036 - val_loss: 7.4440 - val_accuracy: 0.0620\n",
            "Epoch 34/100\n",
            "348/348 [==============================] - 26s 73ms/step - loss: 1.8323 - accuracy: 0.8039 - val_loss: 7.4013 - val_accuracy: 0.0737\n",
            "Epoch 35/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.8244 - accuracy: 0.8053 - val_loss: 7.3793 - val_accuracy: 0.0689\n",
            "Epoch 36/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.8233 - accuracy: 0.8063 - val_loss: 7.4570 - val_accuracy: 0.0705\n",
            "Epoch 37/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.8238 - accuracy: 0.8078 - val_loss: 7.3980 - val_accuracy: 0.0765\n",
            "Epoch 38/100\n",
            "348/348 [==============================] - 25s 71ms/step - loss: 1.8176 - accuracy: 0.8078 - val_loss: 7.4400 - val_accuracy: 0.0680\n",
            "Epoch 39/100\n",
            "348/348 [==============================] - 25s 71ms/step - loss: 1.8191 - accuracy: 0.8090 - val_loss: 7.3807 - val_accuracy: 0.0790\n",
            "Epoch 40/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.8149 - accuracy: 0.8077 - val_loss: 7.4234 - val_accuracy: 0.0701\n",
            "Epoch 41/100\n",
            "348/348 [==============================] - 25s 70ms/step - loss: 1.8192 - accuracy: 0.8069 - val_loss: 7.4246 - val_accuracy: 0.0689\n",
            "Epoch 42/100\n",
            "348/348 [==============================] - 24s 70ms/step - loss: 1.8094 - accuracy: 0.8091 - val_loss: 7.3589 - val_accuracy: 0.0749\n",
            "Epoch 43/100\n",
            "348/348 [==============================] - 25s 71ms/step - loss: 1.8005 - accuracy: 0.8102 - val_loss: 7.4052 - val_accuracy: 0.0745\n",
            "Epoch 44/100\n",
            "348/348 [==============================] - 25s 71ms/step - loss: 1.8037 - accuracy: 0.8093 - val_loss: 7.4248 - val_accuracy: 0.0697\n",
            "Epoch 45/100\n",
            "348/348 [==============================] - 25s 71ms/step - loss: 1.8053 - accuracy: 0.8081 - val_loss: 7.4462 - val_accuracy: 0.0697\n",
            "Epoch 46/100\n",
            "348/348 [==============================] - 24s 70ms/step - loss: 1.7957 - accuracy: 0.8102 - val_loss: 7.4495 - val_accuracy: 0.0676\n",
            "Epoch 47/100\n",
            "348/348 [==============================] - 25s 71ms/step - loss: 1.8077 - accuracy: 0.8092 - val_loss: 7.4443 - val_accuracy: 0.0729\n",
            "Epoch 48/100\n",
            "348/348 [==============================] - 25s 71ms/step - loss: 1.7970 - accuracy: 0.8092 - val_loss: 7.4125 - val_accuracy: 0.0749\n",
            "Epoch 49/100\n",
            "348/348 [==============================] - 25s 71ms/step - loss: 1.8008 - accuracy: 0.8096 - val_loss: 7.4993 - val_accuracy: 0.0717\n",
            "Epoch 50/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.8096 - accuracy: 0.8062 - val_loss: 7.4992 - val_accuracy: 0.0729\n",
            "Epoch 51/100\n",
            "348/348 [==============================] - 25s 71ms/step - loss: 1.7924 - accuracy: 0.8116 - val_loss: 7.4704 - val_accuracy: 0.0664\n",
            "Epoch 52/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.7914 - accuracy: 0.8119 - val_loss: 7.4739 - val_accuracy: 0.0648\n",
            "Epoch 53/100\n",
            "348/348 [==============================] - 25s 71ms/step - loss: 1.7945 - accuracy: 0.8098 - val_loss: 7.4672 - val_accuracy: 0.0741\n",
            "Epoch 54/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.7941 - accuracy: 0.8100 - val_loss: 7.4726 - val_accuracy: 0.0713\n",
            "Epoch 55/100\n",
            "348/348 [==============================] - 25s 71ms/step - loss: 1.7958 - accuracy: 0.8085 - val_loss: 7.4514 - val_accuracy: 0.0628\n",
            "Epoch 56/100\n",
            "348/348 [==============================] - 25s 71ms/step - loss: 1.7823 - accuracy: 0.8128 - val_loss: 7.4765 - val_accuracy: 0.0660\n",
            "Epoch 57/100\n",
            "348/348 [==============================] - 25s 71ms/step - loss: 1.7907 - accuracy: 0.8113 - val_loss: 7.4687 - val_accuracy: 0.0668\n",
            "Epoch 58/100\n",
            "348/348 [==============================] - 25s 71ms/step - loss: 1.7794 - accuracy: 0.8112 - val_loss: 7.4439 - val_accuracy: 0.0689\n",
            "Epoch 59/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.7806 - accuracy: 0.8120 - val_loss: 7.4797 - val_accuracy: 0.0717\n",
            "Epoch 60/100\n",
            "348/348 [==============================] - 25s 71ms/step - loss: 1.7898 - accuracy: 0.8094 - val_loss: 7.4044 - val_accuracy: 0.0697\n",
            "Epoch 61/100\n",
            "348/348 [==============================] - 25s 71ms/step - loss: 1.7819 - accuracy: 0.8121 - val_loss: 7.4226 - val_accuracy: 0.0684\n",
            "Epoch 62/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.7799 - accuracy: 0.8110 - val_loss: 7.4001 - val_accuracy: 0.0741\n",
            "Epoch 63/100\n",
            "348/348 [==============================] - 25s 71ms/step - loss: 1.7669 - accuracy: 0.8140 - val_loss: 7.3943 - val_accuracy: 0.0713\n",
            "Epoch 64/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.7760 - accuracy: 0.8113 - val_loss: 7.3938 - val_accuracy: 0.0680\n",
            "Epoch 65/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.7717 - accuracy: 0.8136 - val_loss: 7.3876 - val_accuracy: 0.0636\n",
            "Epoch 66/100\n",
            "348/348 [==============================] - 25s 71ms/step - loss: 1.7787 - accuracy: 0.8120 - val_loss: 7.4227 - val_accuracy: 0.0664\n",
            "Epoch 67/100\n",
            "348/348 [==============================] - 25s 71ms/step - loss: 1.7746 - accuracy: 0.8112 - val_loss: 7.4244 - val_accuracy: 0.0717\n",
            "Epoch 68/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.7824 - accuracy: 0.8101 - val_loss: 7.4105 - val_accuracy: 0.0680\n",
            "Epoch 69/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.7671 - accuracy: 0.8142 - val_loss: 7.3900 - val_accuracy: 0.0684\n",
            "Epoch 70/100\n",
            "348/348 [==============================] - 25s 71ms/step - loss: 1.7702 - accuracy: 0.8124 - val_loss: 7.3867 - val_accuracy: 0.0737\n",
            "Epoch 71/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.7574 - accuracy: 0.8156 - val_loss: 7.4264 - val_accuracy: 0.0705\n",
            "Epoch 72/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.7571 - accuracy: 0.8126 - val_loss: 7.4393 - val_accuracy: 0.0668\n",
            "Epoch 73/100\n",
            "348/348 [==============================] - 25s 73ms/step - loss: 1.7736 - accuracy: 0.8115 - val_loss: 7.4433 - val_accuracy: 0.0737\n",
            "Epoch 74/100\n",
            "348/348 [==============================] - 25s 73ms/step - loss: 1.7679 - accuracy: 0.8140 - val_loss: 7.4804 - val_accuracy: 0.0680\n",
            "Epoch 75/100\n",
            "348/348 [==============================] - 25s 72ms/step - loss: 1.7676 - accuracy: 0.8121 - val_loss: 7.4200 - val_accuracy: 0.0697\n",
            "Epoch 76/100\n",
            "348/348 [==============================] - 26s 73ms/step - loss: 1.7694 - accuracy: 0.8132 - val_loss: 7.4727 - val_accuracy: 0.0668\n",
            "Epoch 77/100\n",
            "348/348 [==============================] - 26s 73ms/step - loss: 1.7682 - accuracy: 0.8112 - val_loss: 7.3924 - val_accuracy: 0.0749\n",
            "Epoch 78/100\n",
            "348/348 [==============================] - 25s 73ms/step - loss: 1.7605 - accuracy: 0.8152 - val_loss: 7.4592 - val_accuracy: 0.0705\n",
            "Epoch 79/100\n",
            "348/348 [==============================] - 25s 73ms/step - loss: 1.7763 - accuracy: 0.8104 - val_loss: 7.4429 - val_accuracy: 0.0632\n",
            "Epoch 80/100\n",
            "348/348 [==============================] - 25s 73ms/step - loss: 1.7636 - accuracy: 0.8133 - val_loss: 7.4335 - val_accuracy: 0.0680\n",
            "Epoch 81/100\n",
            "348/348 [==============================] - 26s 74ms/step - loss: 1.7531 - accuracy: 0.8147 - val_loss: 7.4505 - val_accuracy: 0.0745\n",
            "Epoch 82/100\n",
            "348/348 [==============================] - 26s 74ms/step - loss: 1.7719 - accuracy: 0.8131 - val_loss: 7.4383 - val_accuracy: 0.0713\n",
            "Epoch 83/100\n",
            "348/348 [==============================] - 26s 74ms/step - loss: 1.7583 - accuracy: 0.8140 - val_loss: 7.4343 - val_accuracy: 0.0668\n",
            "Epoch 84/100\n",
            "348/348 [==============================] - 25s 73ms/step - loss: 1.7629 - accuracy: 0.8142 - val_loss: 7.4495 - val_accuracy: 0.0608\n",
            "Epoch 85/100\n",
            "348/348 [==============================] - 25s 73ms/step - loss: 1.7660 - accuracy: 0.8135 - val_loss: 7.4138 - val_accuracy: 0.0676\n",
            "Epoch 86/100\n",
            "348/348 [==============================] - 26s 74ms/step - loss: 1.7495 - accuracy: 0.8158 - val_loss: 7.4655 - val_accuracy: 0.0672\n",
            "Epoch 87/100\n",
            "348/348 [==============================] - 26s 74ms/step - loss: 1.7560 - accuracy: 0.8147 - val_loss: 7.4424 - val_accuracy: 0.0680\n",
            "Epoch 88/100\n",
            "348/348 [==============================] - 26s 74ms/step - loss: 1.7490 - accuracy: 0.8159 - val_loss: 7.4334 - val_accuracy: 0.0676\n",
            "Epoch 89/100\n",
            "348/348 [==============================] - 26s 74ms/step - loss: 1.7535 - accuracy: 0.8147 - val_loss: 7.4894 - val_accuracy: 0.0640\n",
            "Epoch 90/100\n",
            "348/348 [==============================] - 26s 74ms/step - loss: 1.7633 - accuracy: 0.8150 - val_loss: 7.3854 - val_accuracy: 0.0721\n",
            "Epoch 91/100\n",
            "348/348 [==============================] - 26s 73ms/step - loss: 1.7463 - accuracy: 0.8163 - val_loss: 7.4263 - val_accuracy: 0.0684\n",
            "Epoch 92/100\n",
            "348/348 [==============================] - 26s 74ms/step - loss: 1.7586 - accuracy: 0.8160 - val_loss: 7.4718 - val_accuracy: 0.0656\n",
            "Epoch 93/100\n",
            "348/348 [==============================] - 26s 74ms/step - loss: 1.7510 - accuracy: 0.8155 - val_loss: 7.4171 - val_accuracy: 0.0693\n",
            "Epoch 94/100\n",
            "348/348 [==============================] - 25s 73ms/step - loss: 1.7413 - accuracy: 0.8178 - val_loss: 7.4304 - val_accuracy: 0.0684\n",
            "Epoch 95/100\n",
            "348/348 [==============================] - 26s 74ms/step - loss: 1.7580 - accuracy: 0.8133 - val_loss: 7.4520 - val_accuracy: 0.0656\n",
            "Epoch 96/100\n",
            "348/348 [==============================] - 26s 75ms/step - loss: 1.7492 - accuracy: 0.8171 - val_loss: 7.4876 - val_accuracy: 0.0680\n",
            "Epoch 97/100\n",
            "348/348 [==============================] - 27s 76ms/step - loss: 1.7472 - accuracy: 0.8153 - val_loss: 7.4563 - val_accuracy: 0.0709\n",
            "Epoch 98/100\n",
            "348/348 [==============================] - 27s 76ms/step - loss: 1.7492 - accuracy: 0.8159 - val_loss: 7.4269 - val_accuracy: 0.0701\n",
            "Epoch 99/100\n",
            "348/348 [==============================] - 26s 76ms/step - loss: 1.7358 - accuracy: 0.8175 - val_loss: 7.4679 - val_accuracy: 0.0684\n",
            "Epoch 100/100\n",
            "348/348 [==============================] - 27s 77ms/step - loss: 1.7453 - accuracy: 0.8167 - val_loss: 7.4605 - val_accuracy: 0.0709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('next_word_model.h5')\n",
        "pickle.dump(history, open(\"history.p\", \"wb\"))\n",
        "model = load_model('next_word_model.h5')\n",
        "history = pickle.load(open(\"history.p\", \"rb\"))"
      ],
      "metadata": {
        "id": "D_PNt-jrTaJq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}